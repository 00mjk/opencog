
                    Natural Language Processing
                    ---------------------------

This directory contains an assortment of natural language processing
subsystems, primarily focused on the English language). This includes
language learning code, logical reasoning on facts extracted from
sentences, reference resolution, question answering, natural
language output (generation of syntactically valid sentences),
a chatbot interface, and some AIML interfaces.

How-To
======
The current code "doesn't do anything yet"; rather, it is a platform for
running experiments. Thus, what is contained here should be thought of
as a "bag of parts".  It is up to you to figure out what these parts
are, and to assemble them into something meaningful.  Some fragile
examples have been constructed (e.g. the code in the old-chatbot
directory) but its up to you to do better.

Currently, there are three basic experimental flows that are possible:
the chatbot process, the language-learning process, and the
word-sense-disambiguation (WSD) process.  See the "learn" directory for
more about language learning. See the wsd directory for more about wsd.


Subdirectories (in alphabetical order)
======================================
aiml2oc
-------
Prototype for converting AIML XML into opencog "atomese", so that a
simple opencog script could run AIML dialogs. Under developemnt,
incomplete.

anaphora
--------
Code that picks out pronouns (he, she, it) and offers up a list of
plausible candidates that these might refer to.

chatbot
-------
Scripts for running a chatbot.  Prototypes, incomplete.

diary
-----
Research notes.

irc
---
Interfaces to IRC; provide an easy way to connect opencog to IRC.

learn
-----
Langauge learning code. Goal is to learn any language at all, given
some sufficiently large corpus.  Experiment is in progress, results
are promising but inconclusive. Starved for time.

lg-dict
-------
Code to convert the Link Grammar dictionaries to "atomese". These are
used to construct and validate generated sentences for correct syntax.

microplanning
-------------
A planner for generating natural language sentences from a bag of
dependency-grammar relations. That is, given a set of dependencies
that express an idea, the planner will create a series of sentences that
express the idea, are syntactically correct, are of appropriate length,
and use pronouns in an appropriate way.


old-chatbot
-----------
The old-chatbot directory contains some code to tie opencog NLP
processing to chat systems, and particularly, to IRC chat.  Provides
a high-level implementation of a simple, hard-coded question-answering 
system, resting on the foundations of "seme" and "triples".  It worked,
but had some design difficulties.

pln
---
Misc pln experiments.  Nothing of significance.

question
--------
Obsolete; however, the README there is useful for the general
discussion.

C++ code that implements a basic question-answering algorithm, based on
matching the NL pattern of a question to the NL pattern of an assertion.
If the atomspace contains an assertion such as "John threw the ball", 
then this code can correctly answer the question "Who threw the ball?"
This code is now obsolete, and is not built any more. HOWEVER, the README
does explain the research results, and provides a general introduction to 
question-answering, and should be kept around indefinitely.

refres
------
Some working notes on reference resolution.
The core problem of reference resolution is determining when two words
in a text refer to the same concept. Thus, for example, the same noun,
used in neighboring sentences, probably refers to the same concept.
Alternately, anaphora (he, she, it, etc.) may also be used to refer to
the same concept.

This directory is currently empty, it is meant to someday hold an 
implementation of the Hobbs reference resolution algorithm.

See also the "seme" directory, which contains a practical, working 
implementation of reference resolution. See also the "lexical-attraction"
directory, which outlines a far more general, and hopefully far more
effective approach.

relex2logic
-----------
Converts RelEx output into a logical form.

scm
---
The scm directory contains miscellaneous scheme scripts of general 
utility for NLP work. This includes scripts for pulling out link-grammar 
disjuncts from parse data.

semcor
------
The semcor directory contains some trite SemCor utilities. SemCor
is a WSJ corpus marked up with word senses.  This directory is nearly
empty and is not currently used.

seme
----
Notes on concept formation and reference resolution from linguistic input.
Contains a working implementation of basic reference resolution that is
used by the chatbot.

similarity
----------
The similarity directory contains code related to similarity of word
senses.  Describes plans/code for storing wordnet-derived similarity
measures within OpenCog.

sureal
------
Language generation.

triples
-------
Mostly almost obsolete... replaced by the relex2logic scripts. Still
contains some useful utilities and overall design notes.

The triples directory contains some experimental code for extracting
prepositional triples from text. So, for example: "Lisbon is the 
capital of Portugal" would be turned into "capital_of(Portugal,
Lisbon)".  Such "prepositional relations" extend the usual ontological 
concepts of "is_a", "has_a", "part_of" and "uses" to more general
relations.

Importantly, this directory contains code to convert plain-text
IF...THEN... relations into OpenCog ImplicationLinks. This is one
of the primary achievements of the code here.  Note that the IF...THEN..
structure used is almost identical to the RelEx Frame rules, and so
should be usable for porting RelEx frames to OpenCog.

types
-----
Scripts, etc. to load NLP-specific atom types.

viterbi
-------
A barely-started, mostly abaondoned attempt to create a viterbi parser
for link-grammar (actually, a port of the partly-implemented viterbi
parser in the link-grammar code base, which is more functional than
this one, but is still broken.)

wordnet-import
--------------
The wordnet-import directory contains stand-alone code (i.e. not a part
of opencog) that will walk over the wordnet database, and convert it 
into OpenCog Scheme, which can then be easily loaded into OpenCog.

wsd
---
The wsd directory contains code that implements the Rada Mihalcea 
word-sense disambiguation algorithm.  The Mihalcea algorithm assigns
senses to the words in a sentence, and constructs links between these
different senses. The links are weighted by a word-sense similarity
measure. The result is a graph whose vertices are word-senses, and 
whose edges are these links.  The graph is essentially just a Markov 
chain, and is solved as such, looking for a stationary vector of 
probabilities for the word-sense vertices. The vertices with the 
highest scores are then the most likely meaning for a word.

wsd-post
--------
The wsd-post directory contains code for generating datasets which may
be used for extremely fast (but partial) word-sense disambiguation,
based on grammatical (syntactical) usage. Generating the data-sets can
take cpu-month to cpu-years; the table-lookup can be done in milli or
microseconds.


======================================================================

Input file format
-----------------
This style of input may be produced in one of two ways. It is produced
directly by RelEx, when using the opencog output format: the -o flag
appended to the relex.RelationExtractor executable. The other way is
indirect, but can be considerably more convenient: First, parse text
using the  relex.WebFormat module, to create the "compact file format".
Then, use the relex/src/perl/cff-to-opencog.pl perl script to convert 
this to the final output. 


A Side-note About Syntactic Sugar
===================================
This has been said before, but it bears repeating. Consider the node
type WordInstanceNode, for example:

    (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")

This custom-defined node type should be thought of as syntactic sugar
for the more "primitive" graph:

   (InheritenceLink
        (ConceptNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
        (ConceptNode "WordInstance")
    )

The above InheritenceLink essentially assigns a "type" to the word
instance. This type can be used in the same way that types are
ordinarily used in other programming languages. When managing
hypergraphs, it is almost always easier and faster to locate,
manipulate and delete narrowly typed atoms.

Similarly, for links, we use the syntactic sugar

    (PartOfSpeechLink
        (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
        (DefinedLinguisticConceptNode "noun")
    )

which stands for the more "primitive" construct:

    (EvaluationLink
        (PredicateNode "PartOfSpeech"
            (ListLink
                (WordInstanceNode "cabin@99d22336-6cda-4365-8555-64260ed8bd15")
                (DefinedLinguisticConceptNode "noun")
            )
        )
    )

Notationally, these forms should be considered to be "equivalent"
although there is a bunch of actual code that depends on the one or
the other, and cannot freely intermingle these cases.

Not everything in the RelEx export gets its own specially-declared
node or link type. Those that do not are explicitly declared in the
file "src/nlp/scm/type-definitions.scm"

======================================================================
References:
-----------
"To verbize one's nouns" -- the concept of "Lexical Implication Rules": 
N. Ostler, B.T.S.Atkins, "Predictable Meaning Shift: Some Linguistic
Properties of Lexical Implication Rules", (1991) Proceedings of the
First SIGLEX Workshop on Lexical Semantics and Knowledge Representation

