#LyX 2.0 created this file. For more info see http://www.lyx.org/
\lyxformat 413
\begin_document
\begin_header
\textclass article
\begin_preamble
\usepackage{url} 
\end_preamble
\use_default_options false
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding utf8
\fontencoding global
\font_roman times
\font_sans helvet
\font_typewriter courier
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100

\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref true
\pdf_bookmarks true
\pdf_bookmarksnumbered false
\pdf_bookmarksopen false
\pdf_bookmarksopenlevel 1
\pdf_breaklinks true
\pdf_pdfborder true
\pdf_colorlinks true
\pdf_backref false
\pdf_pdfusetitle true
\papersize default
\use_geometry false
\use_amsmath 2
\use_esint 0
\use_mhchem 0
\use_mathdots 1
\cite_engine basic
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
World Models
\end_layout

\begin_layout Date
Draft Version 0.02 - 14 Sept 2016
\end_layout

\begin_layout Abstract
A description of how OpenCog currently implements self-awareness and world-aware
ness, together with a sketch of how this could be improved and expanded.
 The short-term goal is to create a robot (embodied chatbot) that can hear
 and see, and carry on conversations about perceived objects, as well as
 to carry out conversations about the self.
 These conversations can be verbal, and can also have physical-body performance
 components: body and face expressive movements, such as smiling or waving
 a hand.
 
\end_layout

\begin_layout Section*
Introduction
\end_layout

\begin_layout Standard
The paper proceeds in several steps.
 The first step is to review the overall concept of an 
\begin_inset Quotes eld
\end_inset

internal model
\begin_inset Quotes erd
\end_inset

, and how one can, in principle, interface with it.
 This is followed by a section reviewing the current prototype.
 After this, difficuklties with language are discussed.
\end_layout

\begin_layout Section*
Internal Models
\end_layout

\begin_layout Standard
The basic premise that will be elaborated here is that interacting with
 the world requires the creation of an 
\begin_inset CommandInset href
LatexCommand href
name "internal model"
target "https://en.wikipedia.org/wiki/Internal_model_(motor_control)"

\end_inset

 of the world: in systems theory, this is sometimes called 
\begin_inset Quotes eld
\end_inset

the 
\begin_inset CommandInset href
LatexCommand href
name "good regulator theorem"
target "https://en.wikipedia.org/wiki/Good_regulator"

\end_inset

.
\begin_inset Quotes erd
\end_inset

 An internal model provides the system software with a natural API, a natural
 representation, that various different software components can agree on,
 and use, and manipulate, and reason with.
 
\end_layout

\begin_layout Subsubsection*
AtomSpace
\end_layout

\begin_layout Standard
To achieve a unification of speech, behavior and perception, one must have
 a software infrastructure that allows these to be represented in a unified
 way: that is, the data and algorithms must reside in some unified location.
 From here on out, it is assumed that this unified location is the 
\begin_inset CommandInset href
LatexCommand href
name "OpenCog AtomSpace"
target "http://wiki.opencog.org/w/AtomSpace"

\end_inset

.
 This is stated explicitly, because, in the course of discussion, various
 other technology platforms have been nominated.
 Although one could debate the merits of alternative technologies, this
 will not be done here.
\end_layout

\begin_layout Subsubsection*
Self Model
\end_layout

\begin_layout Standard
The self-model, and together with it, the controversial term 
\begin_inset Quotes eld
\end_inset

self-awareness
\begin_inset Quotes erd
\end_inset

, is here defined to simply be an internal model of the robot itself: both
 of low-level physical variables, such as motor angles, as well as higher-order
 concepts such as 
\begin_inset Quotes eld
\end_inset

I smiled just a few seconds ago
\begin_inset Quotes erd
\end_inset

, or 
\begin_inset Quotes eld
\end_inset

I just said this-and-such
\begin_inset Quotes erd
\end_inset

.
 A basic assumption taken in the following is that the engineering and design
 of the self-model is not any different than the engineering and design
 of the world-model: the data types and access methods are the same for
 both.
 Thus, ideas like 
\begin_inset Quotes eld
\end_inset

I know that my arm is raised
\begin_inset Quotes erd
\end_inset

 are represented in much the same way as 
\begin_inset Quotes eld
\end_inset

I know that there is a box in the corner of the room.
\begin_inset Quotes erd
\end_inset

 Thus, in what follows, the expression 
\begin_inset Quotes eld
\end_inset

internal model
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

model
\begin_inset Quotes erd
\end_inset

 will refer to both the self-model and the world model, there being no particula
r difference.
\end_layout

\begin_layout Subsubsection*
World Model
\end_layout

\begin_layout Standard
Although the above argues that both the self-model and the world-model are
 special cases of the internal model, this is worth more discussion.
 The world model describes not only inanimate objects, such as boxes seen
 in the corner of the room, but includes models of other people.
 In the current software base, this is quite shallow: it is just a list
 of the human faces currently visible to the video camera, and thier 3D
 coordinates.
 The model could include a lot more information: names to be associated
 with the faces, memories of past conversations with those faces, a personality
 profile associated with each face.
 This can be expanded to a general model of 
\begin_inset Quotes eld
\end_inset

other
\begin_inset Quotes erd
\end_inset

, including stereotypes of profession, gender, cultural and geographical
 background, and so on.
\end_layout

\begin_layout Standard
For most of this document, the distinction between models of self, other,
 and the rest of the world does not matter: rather, the discussion centers
 on how to interface such models to perceptions and to actions.
 An vitaly important side topic is how to automatically learn and update
 the model: this is discussed breifly, later, but is not a primary topic.
\end_layout

\begin_layout Subsubsection*
State
\end_layout

\begin_layout Standard
The model is meant to implemented as 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "program state"
target "https://en.wikipedia.org/wiki/State_(computer_science)"

\end_inset


\begin_inset Quotes erd
\end_inset

.
 In the context of OpenCog, this means that state is represented as set
 of 
\begin_inset CommandInset href
LatexCommand href
name "Atoms"
target "http://wiki.opencog.org/w/Atom"

\end_inset

 in the AtomSpace: the AtomSpace is, by definition, a container designed
 specifically for the purpose of holding and storing Atoms.
 Much of this state is to be represented with the 
\begin_inset CommandInset href
LatexCommand href
name "StateLink"
target "http://wiki.opencog.org/w/StateLink"

\end_inset

, and much of the rest with 
\begin_inset CommandInset href
LatexCommand href
name "EvaluationLinks"
target "http://wiki.opencog.org/w/EvaluationLink"

\end_inset

 and 
\begin_inset CommandInset href
LatexCommand href
name "PredicateNodes"
target "http://wiki.opencog.org/w/PredicateNode"

\end_inset

.
 The precise details follow what is currently the standard best-practices
 in OpenCog.
 That is, there is no particular proposal here to change how things are
 already handled and coded in OpenCog, although a goal here is to clarify
 numerous issues.
\end_layout

\begin_layout Standard
It is critically important that state be represented as Atoms, as, otherwise,
 there is no other practical way of providing access to that state by all
 of the various subsystems that need to examine and manipulate that state.
 This is an absolutely key insight that often seems to be lost: if the state
 data is placed in some C++ or Python or Scheme or Haskel class, it is essential
ly 
\begin_inset Quotes eld
\end_inset

invisible
\begin_inset Quotes erd
\end_inset

 to the very system that needs to work with it.
 This applies to any kind of state: it could be chat state (words and sentences)
 or visual state (pixels, 3D coordinate locations): if it is not represented
 as Atoms, then the myriad learning and reasoning algorithms cannot effectively
 act on this state.
 This is an absolutely key point, and is one reason why non-AtomSpace infrastruc
tures are not being considered: they lack the representational uniformity
 and infrastructure needed for implementing learning and reasoning.
\end_layout

\begin_layout Standard
However, the AtomSpace does have certain peculiar performance characteristics
 and limitations that make it not suitable for all data: for example, one
 would never want to put raw video or audio into it.
 Yet, one does need access to such data, and so specific subsystems can
 be created to efficiently handle special-purpose data.
 A primary example of this is the 
\begin_inset CommandInset href
LatexCommand href
name "SpaceTime"
target "http://wiki.opencog.org/w/SpaceServer"

\end_inset

 subsystem, which represents the 3D locations of objects in an 
\begin_inset CommandInset href
LatexCommand href
name "OctTree"
target "https://en.wikipedia.org/wiki/Octree"

\end_inset

 format, as well as offering a time component.
 Although the SpaceTime subsystem can store data in a compact internal format,
 it is not, however, exempt from having to work with Atoms: data must be
 accessible as Atoms, and suitable query API's must be provided.
 In this example: it is possible to query for nearby time-like events, or
 to answer questions about whether one object is nearer or farther, or maybe
 bigger or smaller, than another.
\end_layout

\begin_layout Subsubsection*
Model and Control
\end_layout

\begin_layout Standard
It is not sufficient to create an internal model of the world, and represent
 it as state: a control API or control language to manipulate that state
 must also be provided.
 The control is the active snippet of code that performs the actions needed
 to update the internal model.
 It can be thought of as the 
\begin_inset Quotes eld
\end_inset

control
\begin_inset Quotes erd
\end_inset

 aspect of the 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "model-view-controller"
target "https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller"

\end_inset


\begin_inset Quotes erd
\end_inset

 (MVC) paradigm from GUI programming.
 There are both engineering and philosophical reasons for having a control
 API.
 The engineering reasons include things like code-reuse, error-checking,
 encapsulation and ease-of-use.
 The philosophical reason is that a control API provides a shim between
 the world of static data, and the world of action and movement.
 That is, as events occur in time, and as the world is in flux, so must
 also be the internal model.
 
\end_layout

\begin_layout Standard
It is useful to think of the control API as a collections of 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

 that can be applied to 
\begin_inset Quotes eld
\end_inset

objects
\begin_inset Quotes erd
\end_inset

 (see 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Model-and-Control"

\end_inset

).
 In object-oriented programming, these 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 are usually called 
\begin_inset Quotes eld
\end_inset

methods
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

messages
\begin_inset Quotes erd
\end_inset

.
 In what follows, these will often be called 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

, or possibly 
\begin_inset Quotes eld
\end_inset

meta-verbs
\begin_inset Quotes erd
\end_inset

 (XXX TODO: we need a good name for this).
 There is an important reason for this choice of terminology.
 First, due to the nature of how data is represented in the AtomSpace, it
 is the case that some given action can be applied to a large swath of the
 data.
 That is, most actions are NOT tightly coupled to the data they are manipulating
, but are quite general.
 This means that the object-oriented paradigm does not work well with our
 concept of 
\begin_inset Quotes eld
\end_inset

internal model
\begin_inset Quotes erd
\end_inset

: its not like there are many different kinds of objects, and they all need
 to have methods.
 More accurately, there are only a few kinds, and many (most?) actions are
 in principle (de facto?) capable of manipulating many (most?) kinds of
 state.
 The OO paradigm does not provide a good way of thinking about what goes
 on in the atomspace.
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\align center
\begin_inset Caption

\begin_layout Plain Layout
Model and Control
\begin_inset CommandInset label
LatexCommand label
name "fig:Model-and-Control"

\end_inset


\end_layout

\end_inset


\begin_inset Graphics
	filename MVC.eps
	width 70col%

\end_inset


\end_layout

\begin_layout Plain Layout
The control API alters the model.
 It does so by applying 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 to the model state.
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
offset "0.5ex"
width "100col%"
height "1pt"

\end_inset


\end_layout

\begin_layout Plain Layout

\end_layout

\end_inset


\end_layout

\begin_layout Standard
Another handy reason for why these 
\begin_inset Quotes eld
\end_inset

actions
\begin_inset Quotes erd
\end_inset

 can be called 
\begin_inset Quotes eld
\end_inset

verbs
\begin_inset Quotes erd
\end_inset

 is that they are really 
\begin_inset Quotes eld
\end_inset

potential actions
\begin_inset Quotes erd
\end_inset

: nothing happens until they are performed.
 However, they can still be talked about, and reasoned about, and even learned:
 that is, the actions themselves can also be represented with Atoms, thus
 allowing the reasoning subsystem to make inferences such as 
\begin_inset Quotes eld
\end_inset

if I do X, then Y will happen
\begin_inset Quotes erd
\end_inset

 e.g.
 
\begin_inset Quotes eld
\end_inset

if I stick out my tongue, people will laugh, or maybe they will get offended
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
In the same way that it was argued that model state must be represented
 in terms of OpenCog Atoms, or 
\begin_inset Quotes eld
\end_inset

atomese
\begin_inset Quotes erd
\end_inset

, so too must be the verbs.
 That is, the 
\begin_inset Quotes eld
\end_inset

control API
\begin_inset Quotes erd
\end_inset

 is not some C++ code (or python or scheme or Haskel...) but rather, it is
 also a collection of Atoms.
 Again, the reason for this is to allow the system to automatically generate
 new verbs, by means of learning, as well as to reason about the results
 of actions.
 Another key idea is that this allows actions to be combined and composed,
 in sequential or parallel order, with different timing.
 That is, the actions are primitives that can be composed into performances,
 that play out over time.
 Representing these as atomese how such composition and performance-scripting
 can be achieved.
\end_layout

\begin_layout Subsubsection*
Control language
\end_layout

\begin_layout Standard
Following the idea of needing to script actions to control behaviors leads
 one naturally to the need for concepts such as modifiers, which come in
 various forms, including 
\begin_inset Quotes eld
\end_inset

adjectives
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

adverbs
\begin_inset Quotes erd
\end_inset

.
 So for example, if 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 corresponds to the atomese describing a robot arm, and 
\begin_inset Quotes eld
\end_inset

raise
\begin_inset Quotes erd
\end_inset

 is an action that can be applied to 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 (that is, the atomese for performing that action), then it is plausible
 to want to say 
\begin_inset Quotes eld
\end_inset

raise the left arm quickly
\begin_inset Quotes erd
\end_inset

.
 Here, 
\begin_inset Quotes eld
\end_inset

quickly
\begin_inset Quotes erd
\end_inset

 is the atomese needed for modulating the rate at which the motors controlling
 the arm are run.
 Likewise, 
\begin_inset Quotes eld
\end_inset

left
\begin_inset Quotes erd
\end_inset

 is the atomese specifier indicating which collection of motors are to be
 controlled.
\end_layout

\begin_layout Standard
Thus, the concept of a 
\begin_inset Quotes eld
\end_inset

control language
\begin_inset Quotes erd
\end_inset

 arises naturally within the system.
 The control language is NOT English! Although it does have a grammar, the
 grammar is NOT that of English.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Control Language
\begin_inset CommandInset label
LatexCommand label
name "fig:Control-Language"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align center
\begin_inset Graphics
	filename language.eps
	width 80col%

\end_inset


\end_layout

\begin_layout Plain Layout
The control language can have a non-trivial grammar associated with it;
 for example, one can 
\begin_inset Quotes eld
\end_inset

turn to the left
\begin_inset Quotes erd
\end_inset

, but one cannot 
\begin_inset Quotes eld
\end_inset

turn to the eye-blink
\begin_inset Quotes erd
\end_inset

 -- they eye-blink animation not being valid with the turn directive.
 The language can control different systems: the physical body or 
\begin_inset Quotes eld
\end_inset

plant
\begin_inset Quotes erd
\end_inset

, the internal model (or self-model, in this case), as well as models representi
ng hypothetical future behavior, or even models that represent memories
 of the past.
 This is possible because the plant and models all use the same representation
 scheme, and thus, the language can act on each equally well.
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
offset "0.5ex"
width "100col%"
height "1pt"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The need for a control language seems to be unavoidable: it is important
 to be able to specify motor speeds, etc.
 Now, if one had an object-oriented system, then one would have a 
\begin_inset Quotes eld
\end_inset

motor
\begin_inset Quotes erd
\end_inset

 object (or an 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 object composed of 
\begin_inset Quotes eld
\end_inset

motor
\begin_inset Quotes erd
\end_inset

 objects), which had a 
\begin_inset Quotes eld
\end_inset

slot
\begin_inset Quotes erd
\end_inset

 (or 
\begin_inset Quotes eld
\end_inset

method
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

message
\begin_inset Quotes erd
\end_inset

) called 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

, and to control the arm, one would send the 
\begin_inset Quotes eld
\end_inset

fast
\begin_inset Quotes erd
\end_inset

 message to the 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

 slot (or 
\begin_inset Quotes eld
\end_inset

speed
\begin_inset Quotes erd
\end_inset

 method) on the 
\begin_inset Quotes eld
\end_inset

arm
\begin_inset Quotes erd
\end_inset

 instance.
 There's nothing particularly wrong with this view, except for the following
 points.
 If the OO language was C++, then the classes and methods must be known
 at compile time: new classes, methods and messages cannot be dynamically
 created, at run-time.
 If the OO language was JavaScript, then many of these issues go away: JavaScrip
t does allow new methods to be added, at run-time, to pre-existing objects.
 Indeed, in many ways, OpenCog Atomese resembles JavaScript.
 In particular, the JavaScript members are very similar to OpenCog Atoms,
 in that, at run-time, new members and methods can be added to objects.
 One could also say that OpenCog Atomese is a lot like JSON, in that one
 can specify arbitrary state structures in JSON.
\end_layout

\begin_layout Standard
There are also some important ways in which atomese differs from JavaScript
 or JSON: atomese allows introspection, i.e.
 it allows for some atoms to control and operate on other atoms, which is
 not possible in JSON.
 Atomese also provides a query language, which JSON does not provide (To
 understand what atomese does, one might imagine writing a SparQL or SQL
 wrapper to query the contents of giant blobs of JSON, or possibly dumping
 large blobs of JSON into Apache Solr or Lucene or Cassandra).
 Atomese also has other language features (it is Prolog-like, it is ML-like)
 that are lacking in JavaScript.
 
\end_layout

\begin_layout Standard
Anyway, the goal here is not to debate the design of atomese, but rather
 to indicate that motor-control directives behave more like a language,
 than like an API: thus, it is more correct to think of the system as offering
 a 
\begin_inset Quotes eld
\end_inset

control language
\begin_inset Quotes erd
\end_inset

 rather than a 
\begin_inset Quotes eld
\end_inset

control API
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Subsubsection*
Internal model vs.
 physical body
\end_layout

\begin_layout Standard
The control language needs to control two distinct things: it needs to control
 both the internal model, and also the physical body! That is, a directive
 such as 
\begin_inset Quotes eld
\end_inset

raise the left arm
\begin_inset Quotes erd
\end_inset

 can be used to update the internal model, and it can also be used to control
 the motors on the actual physical body (
\begin_inset Quotes eld
\end_inset

the plant
\begin_inset Quotes erd
\end_inset

, in control-theory terminology).
 There may also be more than one internal model: in control theory, it is
 not uncommon to have a 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "forward model"
target "https://en.wikipedia.org/wiki/Internal_model_(motor_control)#Forward_models"

\end_inset


\begin_inset Quotes erd
\end_inset

, which is used to estimate what might happen if an action was performed,
 or an 
\begin_inset Quotes eld
\end_inset

inverse model
\begin_inset Quotes erd
\end_inset

 as an interface to the physical body.
 Both of these are distinct from the internal model, which models the current
 state, as opposed to some hypothetical future state.
\end_layout

\begin_layout Standard
Other models are possible: this includes memories of past events, where
 some remembered actions might be re-enacted: in this case, the remembered
 actions can be replayed on a remembered model, to reconstruct what happened
 (for example, to answer questions about those events).
 Another possibility is that of predicting the future, where a sequence
 of actions are played out on a model of the hypothetical future, to see
 what might happen.
 In such a case, there might be a model of the audience, as well as a model
 of the self: one is interested in predicting how the audience might react
 to a particular action.
\end_layout

\begin_layout Standard
Rather than inventing a new language for each of these different systems,
 it is convenient to be able to use the same language.
 The under-the-covers implementation is different: in one case, motors must
 be moved; in another case, the model must be updated.
 In either case, the verbs, nouns, adjectives and adverbs should be the
 same.
 (In control theory, this is termed the 
\begin_inset Quotes eld
\end_inset

efference copy
\begin_inset Quotes erd
\end_inset

).
 This is possible as long as the different systems use the same underlying
 design scheme: as long as the underlying hyper-graphs have the same structure,
 they can be manipulated the same way, never mind that one might represent
 the physical body, and another the self-model.
\end_layout

\begin_layout Subsubsection*
English language interfaces
\end_layout

\begin_layout Standard
Given the above description of the concept of 
\begin_inset Quotes eld
\end_inset

model
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

control language
\begin_inset Quotes erd
\end_inset

, one can now imagine that controlling the robot using the English language
 might not be too hard: just translate English to the internal control language,
 and one is done! Thus, for example, it is easy to imagine that simple English
 sentences, such as 
\begin_inset Quotes eld
\end_inset

look left!
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

pretend you're happy!
\begin_inset Quotes erd
\end_inset

, can be converted to the control langauge.
 
\end_layout

\begin_layout Standard
There are several ways to accomplish this.
 There is a simple, brute-force approach: create templates such as 
\begin_inset Quotes eld
\end_inset

Look ____
\begin_inset Quotes erd
\end_inset

 or 
\begin_inset Quotes eld
\end_inset

Pretend you're ____
\begin_inset Quotes erd
\end_inset

 and implement a fill-in-the-blanks algorithm.
 Simple string matching will suffice, and (for example) AIML excels at this
 kind of string-search and string-matching.
 This approach is sufficient to tell the robot to look in different directions,
 and to make different facial expressions.
\end_layout

\begin_layout Standard
A core premise of what follows is that brute-force string-matching or string-tem
plating is NOT sufficient for more complex, more abstract conversations.
 For that, a syntactic analysis of the sentence is needed.
 Thus, although there is plenty of room and utility for string-matching
 in the natural-language subsystem, this will NOT be the primary focus of
 this document (nor is it used in the prototype).
 Complex conversational abilities are anticipated, and so are planned for,
 from the start.
\end_layout

\begin_layout Standard
The prototye does perform syntactic analysis using the Link Grammar parser.
 It could have used RelEx or Relex2Logic, but does not, for reasons explained
 later.
\end_layout

\begin_layout Standard
If one has a syntactic analyzer, then translation can be performed by extracting
 the syntax of a given English-language sentence, and re-writing it into
 an equivalent control-language structure.
 Along the way, specific English-language words and phrases are remapped
 to equivalent control-language atoms.
\end_layout

\begin_layout Subsubsection*
Link Grammar
\end_layout

\begin_layout Standard
The syntax of the English-language sentence is extracted by parsing the
 input sentence with the 
\begin_inset CommandInset href
LatexCommand href
name "Link Grammar parser"
target "http://www.abisource.com/projects/link-grammar/"

\end_inset

 (
\begin_inset CommandInset href
LatexCommand href
name "wikipedia"
target "https://en.wikipedia.org/wiki/Link_grammar"

\end_inset

).
 There are certainly many other natural-language parsers out there, including
 famously the Stanford parser, Google's Parsey-McParseface, and any number
 of phrase-structure parsers.
 Link Grammar is used because it fits particularly well with the theory
 of Atomese, and because it has particularly high accuracy and very broad
 coverage.
 
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status collapsed

\begin_layout Plain Layout
\begin_inset Caption

\begin_layout Plain Layout
Example Link Grammar Parse
\begin_inset CommandInset label
LatexCommand label
name "fig:Example-Link-Grammar"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset VSpace defskip
\end_inset


\end_layout

\begin_layout Plain Layout
\align left
\begin_inset Graphics
	filename lg.eps
	width 80col%
	BoundingBox 0bp -20bp 500bp 80bp

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

                        +----Js---+
\end_layout

\begin_layout Plain Layout

         +---Wi---+-MVp-+   +Ds**c+
\end_layout

\begin_layout Plain Layout

         |        |     |   |     |
\end_layout

\begin_layout Plain Layout

     LEFT-WALL look.v to.r the left.n
\end_layout

\end_inset


\end_layout

\begin_layout Plain Layout
The above illustrates a parse of the sentence 
\begin_inset Quotes eld
\end_inset

Look to the left
\begin_inset Quotes erd
\end_inset

 (as post-script and ascii-graphics).
 It consists of a collection of typed links or edges connecting pairs of
 words.
 The 
\family typewriter
Wi
\family default
 link points at the main verb of the sentence, and indicates that it is
 an imperative.
 The 
\family typewriter
MVp
\family default
 link attaches the verb to a verb-modifier, in this case, to the preposition
 
\begin_inset Quotes eld
\end_inset

to
\begin_inset Quotes erd
\end_inset

.
 The 
\family typewriter
Js
\family default
 link connects the preposition to it's object, in this case, the noun 
\begin_inset Quotes eld
\end_inset

left
\begin_inset Quotes erd
\end_inset

 (prepositions always have objects).
 The 
\family typewriter
Ds**c
\family default
 link joins the noun to the determiner 
\begin_inset Quotes eld
\end_inset

the
\begin_inset Quotes erd
\end_inset

.
 Both 
\family typewriter
Js
\family default
 and 
\family typewriter
Ds
\family default
 indicate that the nouns is singular, and the 
\family typewriter
**c
\family default
 indicates that it begins with a consonant (that is, phonetic analysis is
 also provided).
\end_layout

\begin_layout Plain Layout
\begin_inset CommandInset line
LatexCommand rule
offset "0.5ex"
width "100col%"
height "1pt"

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The Link Grammar parser discovers relationships between the words in a sentence,
 and marks up those relationships with links connecting pairs of words.
 These links have a type or kind, indicating the relationship between the
 words -- typically, subject, object, adjectival-modifier, adverbial-modifier,
 prepositional-object and so on.
 This is illustrated in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-Link-Grammar"

\end_inset

.
 The relationships, taken together, can be understood to form a directed
 graph, often a tree.
 Most links have an implicit directionality in them.
 The graph does sometimes have cycles: these constrain the parse choices.
 
\end_layout

\begin_layout Standard
The graph fully encodes the syntactic structure of the parsed sentence,
 as well as a fair amount of the semantic structure, encoded in the so-called
 
\begin_inset Quotes eld
\end_inset

disjuncts
\begin_inset Quotes erd
\end_inset

.
 The disjuncts are the graph-duals to the linkages.
 Thus, in the figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-Link-Grammar"

\end_inset

, it can be seen that the word 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 has a link 
\family typewriter
Wi
\family default
 to the left, and a link 
\family typewriter
MVp
\family default
 to the right: these two form a disjunct 
\family typewriter
Wi- & MVp+
\family default
, with the plus and minus signs indicating linkage to the right and left.
 Given only this disjunct, and nothing else - not even the word itself,
 one can already deduce that the word must be a verb, and that it must be
 an imperative, and that it will take a preposition, and thus, a prepositional
 object.
 Thus, the disjunct 
\family typewriter
Wi- & MVp+
\family default
 acts as a fine-grained part-of-speech, and this carries semantic information.
 That is, the meaning of a word is correlated with the part-of-speech: this
 is obvious simply by observing that dictionaries organize word-meanings
 by parts-of-speech.
 The disjunct offers a particularly fine-grained distinction, and thus is
 more strongly correlated with meaning.
\end_layout

\begin_layout Standard
Note that there are 
\begin_inset Quotes eld
\end_inset

costs
\begin_inset Quotes erd
\end_inset

 or weights associated with different disjuncts.
 These can be interpreted as log-probabilities, and so the parse system,
 as a whole, has probabilistic or Markovian aspects associated with it.
 This play a minor role, at this stage.
\end_layout

\begin_layout Subsubsection*
Graph rewriting
\end_layout

\begin_layout Standard
The translation process proceeds by taking the syntactic-parse graph, such
 as 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-Link-Grammar"

\end_inset

, and converting it into an equivalent control-language graph, such as in
 figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Control-Language"

\end_inset

.
 The conversion of one graph into another is accomplished via 
\begin_inset CommandInset href
LatexCommand href
name "graph-rewriting"
target "https://en.wikipedia.org/wiki/Graph_rewriting"

\end_inset

.
 The Opencog AtomSpace has a powerful and sophisticated graph-rewriting
 engine built into it, called the 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "pattern matcher"
target "http://wiki.opencog.org/w/Pattern_matching"

\end_inset


\begin_inset Quotes erd
\end_inset

; it can easily convert graphs of one shape into another, even when the
 graphs contain variables in them (that is, use variables to represent subgraphs
).
 
\end_layout

\begin_layout Standard
The graph rewriting is specified by writing down 
\begin_inset Quotes eld
\end_inset

rules
\begin_inset Quotes erd
\end_inset

 that indicate the shape of the expected input graph, and the kind of output
 graph that should be generated, when a match is found.
 These rules are usually specified in the form of a 
\begin_inset CommandInset href
LatexCommand href
name "BindLink"
target "http://wiki.opencog.org/w/SatisfactionLink_and_BindLink"

\end_inset

, which can be thought of as an if-statement: 
\begin_inset Quotes eld
\end_inset

if graph p is recognized, then generate graph q
\begin_inset Quotes erd
\end_inset

.
 Alternately, they can be thought of as an implication 
\begin_inset Formula $p\to q$
\end_inset

, or, with variables, 
\begin_inset Formula $p(x)\to q(x)$
\end_inset

.
\end_layout

\begin_layout Standard
To provide a worked example: to rewrite figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-Link-Grammar"

\end_inset

 into figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Control-Language"

\end_inset

, one creates a rule 
\begin_inset Quotes eld
\end_inset

IF word x has disjunct 
\family typewriter
Wi- & MVp+
\family default
 and word x is 'turn' and word y has disjunct 
\family typewriter
Ds**c- & Js-
\family default
, THEN create control-language graph 'turn(y)'
\begin_inset Quotes erd
\end_inset

.
 The prototype contains a rule of roughly this form.
\end_layout

\begin_layout Subsubsection*
Next steps
\end_layout

\begin_layout Standard
There are additional important concepts that are required to correctly implement
 a fully working system.
 Before discussing these, it is worth reviewing the current prototype, as
 it illustrates the above concepts in a specific, concrete manner.
 The issues encountered during prototyping also serve as an introduction
 to problems that must be solved in the full system.
\end_layout

\begin_layout Section*
Prototype Review
\end_layout

\begin_layout Standard
The prototype of the above-described system is located in 
\begin_inset CommandInset href
LatexCommand href
name "github"
target "https://github.com/opencog/opencog"

\end_inset

, in the 
\begin_inset CommandInset href
LatexCommand href
name "nlp/chatbot-eva"
target "https://github.com/opencog/opencog/blob/21ad879d85d31013e59870b895bb0a0aef97242c/opencog/nlp/chatbot-eva"

\end_inset

 directory.
 It naturally splits into three pieces.
 These are:
\end_layout

\begin_layout Itemize
An implementation of the self-model and the control language.
\end_layout

\begin_layout Itemize
An English-to-control-language translation layer.
\end_layout

\begin_layout Itemize
A rule engine, to drive the system.
\end_layout

\begin_layout Standard
These are each reviewed, below.
 There are assorted issues, especially in the translation layer; these serve
 to anchor later discussion.
\end_layout

\begin_layout Subsubsection*
Control language prototype
\end_layout

\begin_layout Standard
The control language is implemented in 
\begin_inset CommandInset href
LatexCommand href
name "knowledge.scm"
target "https://github.com/opencog/opencog/blob/21ad879d85d31013e59870b895bb0a0aef97242c/opencog/nlp/chatbot-eva/knowledge.scm"

\end_inset

.
 All of the previous discussion is made concrete in this file, and a review
 of this file is strongly recommended.
 This is where the 
\begin_inset Quotes eld
\end_inset

rubber meets the road
\begin_inset Quotes erd
\end_inset

, where things actually happen.
\end_layout

\begin_layout Standard
Lines 80 thru 120 illustrate how spatial directions are grounded in specific
 x,y,z coordinates.
 Lines 127 thru 132 associate specific English-language words to these direction
s.
 Lines 135-139 group the control-language direction names into a single
 kind (in this case, into the class 
\begin_inset Quotes eld
\end_inset

schema-direction
\begin_inset Quotes erd
\end_inset

).
 This will be used later, to make sure that the 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

turn
\begin_inset Quotes erd
\end_inset

 verbs can only take the direction-kind, as opposed to the facial-expression-kin
d.
 This forms the foundation of a crude grammar for the control language:
 it will not be legal to say 
\begin_inset Quotes eld
\end_inset

turn your head to face in the happy direction
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
Lines 145-149 give the two kinds to looking-turning control verbs.
 Lines 166-170 define the control-language grammar: the only valid way to
 move the robot head is to specify either the 
\begin_inset Quotes eld
\end_inset

turn
\begin_inset Quotes erd
\end_inset

 or the 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 verb, followed by a direction-kind.
 (In the current Blender animation subsystem, 
\begin_inset Quotes eld
\end_inset

turn
\begin_inset Quotes erd
\end_inset

 rotates the entire head (turning the neck) while 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 only moves the eyes.)
\end_layout

\begin_layout Standard
Lines 173-213 duplicate the earlier portion of the file, and implement the
 control language for the internal model (here called the 
\begin_inset Quotes eld
\end_inset

self-model
\begin_inset Quotes erd
\end_inset

, because it is modeling the robot itself).
\end_layout

\begin_layout Standard
Lines 216-306 define the control-adverbs, in one-to-one correspondence to
 the Blender animation names for facial expressions.
 There is exactly *one* control-adverb for each animation: it is not desirable
 to have synonyms in this layer.
 Line 316 defines the one and only control-verb for facial expressions:
 this is the 
\begin_inset Quotes eld
\end_inset

perform a facial animation
\begin_inset Quotes erd
\end_inset

 verb.
\end_layout

\begin_layout Standard
Lines 321-336 associate fifteen different English-language words with this
 one control-verb.
 This is because, in English, synonyms are common and pervasive: it is quite
 natural to say 
\begin_inset Quotes eld
\end_inset

Look happy!
\begin_inset Quotes erd
\end_inset

 
\begin_inset Quotes eld
\end_inset

Act happy!
\begin_inset Quotes erd
\end_inset

 
\begin_inset Quotes eld
\end_inset

Be happy!
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

Emote happiness!
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

Portray happiness!
\begin_inset Quotes erd
\end_inset

 and mean the same thing.
 Thus, all of these different English-language words are mapped to the same
 control-verb.
\end_layout

\begin_layout Standard
Lines 338-511 associate more than one hundred(!) different English-language
 words with the fifteen-or-so different Blender animation names.
 For example, 
\begin_inset Quotes eld
\end_inset

perplexity
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

puzzlement
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

confusion
\begin_inset Quotes erd
\end_inset

 are all valid synonyms for the 
\begin_inset Quotes eld
\end_inset

confused
\begin_inset Quotes erd
\end_inset

 animation.
\end_layout

\begin_layout Standard
Lines 520-531 group together the different Blender facial-expression animations
 into a single animation-kind.
 
\end_layout

\begin_layout Standard
Lines 534-538 define the control-grammar for performing a facial animation:
 it must necessarily consist of the single perform-facial-animation control-verb
, and one of the fifteen Blender facial-animation adverbs.
 No other combination is possible: thus one cannot make the control-language
 statement 
\begin_inset Quotes eld
\end_inset

emote leftness
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
These control-grammar rules not only define what it is possible to do with
 the robot, but they also disambiguate certain English-language expressions.
 Very specifically, one can say, in English, 
\begin_inset Quotes eld
\end_inset

Look left!
\begin_inset Quotes erd
\end_inset

 and 
\begin_inset Quotes eld
\end_inset

Look happy!
\begin_inset Quotes erd
\end_inset

.
 The English-language verb 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 is associated with both the control-language turn-verb (line 199) and also
 the control-language express-verb (line 335).
 Which of these two meanings for the English-language word 
\begin_inset Quotes eld
\end_inset

look
\begin_inset Quotes erd
\end_inset

 is intended becomes clear only after the English has been translated into
 control-language.
 The control grammar allows only one, or the other meaning, depending on
 how it is combined with the other control-words.
 In particular, this means that (in this prototype), the control-words are
 always and necessarily unique and unambiguous in their 
\begin_inset Quotes eld
\end_inset

meaning
\begin_inset Quotes erd
\end_inset

.
 The control words provide 
\begin_inset Quotes eld
\end_inset


\begin_inset CommandInset href
LatexCommand href
name "grounding"
target "https://en.wikipedia.org/wiki/Symbol_grounding_problem"

\end_inset


\begin_inset Quotes erd
\end_inset

 for meaning.
\end_layout

\begin_layout Standard
Lines 540-560 duplicate the above, but are used for controlling the self-model,
 instead of controlling Blender.
\end_layout

\begin_layout Standard
Lines 570-680 (end of file) repeat the previous structures, but are used
 to control the Blender gesture-animations (blinking, nodding, shaking,
 yawning).
 The very same concepts apply.
 
\end_layout

\begin_layout Subsubsection*
DRAFT VERSION 0.02
\end_layout

\begin_layout Standard
This is a draft.
 Everything above is in some mostly-finished state.
 Everything below is in outline format.
\end_layout

\begin_layout Subsubsection*
Translation prototype
\end_layout

\begin_layout Standard
The translation consists of a set of hand-crafted rules that can recognize
 specific kinds of English-language sentences, and convert these into the
 internal-language forms.
 These are implemented in the file 
\begin_inset CommandInset href
LatexCommand href
name "imperative-rules.scm"
target "https://github.com/opencog/opencog/blob/21ad879d85d31013e59870b895bb0a0aef97242c/opencog/nlp/chatbot-eva/imperative-rules.scm"

\end_inset

.
 For example, the English sentence 
\begin_inset Quotes eld
\end_inset

look left
\begin_inset Quotes erd
\end_inset

 is recognized by the 
\family typewriter
look-rule-1
\family default
 pattern, lines 176-189.
 The sentence 
\begin_inset Quotes eld
\end_inset

look to the left
\begin_inset Quotes erd
\end_inset

 is recognized by the 
\family typewriter
look-rule-2
\family default
 pattern, lines 191-208.
 Both of these patterns specify several synonyms for the English verb.
 The pattern of the English sentences is recognized in lines 186-188 and
 lines 205-206.
 The lg-links 
\family typewriter
MVa
\family default
, 
\family typewriter
MVp
\family default
, 
\family typewriter
Js
\family default
, 
\family typewriter
Ju
\family default
 come from the Link Grammar parse of the sentence; these are already illustrated
 in figure 
\begin_inset CommandInset ref
LatexCommand ref
reference "fig:Example-Link-Grammar"

\end_inset

.
 There is a fair amount of monkey-business being done to make these rules
 relatively easy to write.
 One issue is that the atomese representation of the Link Grammar perses
 is fairly turgid (the 
\begin_inset CommandInset href
LatexCommand href
name "RelEx Atomese format"
target "http://wiki.opencog.org/w/RelEx_OpenCog_format"

\end_inset

); complexities arise due to the need to represent multiple distinct sentences,
 as well as to distinguish the use of the same word in two different places
 in a sentence: these are 
\begin_inset Quotes eld
\end_inset

word instances
\begin_inset Quotes erd
\end_inset

.
 Thus, an imperative-sentence utility is provided in lines 130-172; if that
 utility is not used, then the two look-rules are more verbose, and are
 shown in lines 48-90 and 92-128.
 It is useful to compare these, to get the 
\begin_inset Quotes eld
\end_inset

big picture
\begin_inset Quotes erd
\end_inset

 of the rule format.
 
\end_layout

\begin_layout Standard
There are several technical issues that crop up, at this point.
 These are central to later development, and so are discussed in detail
 here.
\end_layout

\begin_layout Standard
One is that the
\end_layout

\begin_layout Standard
issue: learning vs.
 hand-crafting, obtaining synonymous phrases, not just synonymous words.
\end_layout

\begin_layout Standard
issue: its LG not R2L
\end_layout

\begin_layout Standard
issue: using openpsi to discover and apply rules.
 This is like using openpsi in general, to pick through non-verbal stimulus.
\end_layout

\begin_layout Standard
issue: fuzzy matching, partial matching
\end_layout

\begin_layout Standard
issue: picking out sentences attached to an anchor, vs other processing
 pipeline designs.
\end_layout

\begin_layout Standard
todo -- the verb synonyms shouyld not be needed!? as they can be gotten
 from the synonym lists for tha control-action language...
\end_layout

\begin_layout Subsubsection*
Question-answering
\end_layout

\begin_layout Standard
Answering questions about self and the world.
 Also has been prototyped.
 Its like the 
\begin_inset Quotes eld
\end_inset

view
\begin_inset Quotes erd
\end_inset

 part of MVC -- the internal state has to be 
\begin_inset Quotes eld
\end_inset

viewed
\begin_inset Quotes erd
\end_inset

 easily, in order to be queried.
 Thus, there are a set of 
\begin_inset Quotes eld
\end_inset

standardized state queries
\begin_inset Quotes erd
\end_inset

, analogous to the control language.
 Running these queries returns yes/no answers (truth queries) or multi-valued
 data (e.g.
 look-at direction) or more complex structures (sequences of actions that
 had been performed in the past) 
\end_layout

\begin_layout Standard
There are two translation layers that are needed here: first, to convert
 English to the internal query language, second, to convert the response
 back to English.
 If the response is of the right form, then SuReal can be used to perform
 the final conversion.
 Right now, the query language is not generating SuReal-compatible results.
\end_layout

\begin_layout Subsubsection*
World model
\end_layout

\begin_layout Standard
Right now, there is only a self-model.
 A world-model is needed, so we can talk about that.
 Well --there is a world model -- currently, it consists of the visible
 faces in the environment.
 It needs to get bigger.
\end_layout

\begin_layout Subsubsection*
Action Orchestration
\end_layout

\begin_layout Standard
Carrying out multiple things at once; using the internal model to do this.
\end_layout

\begin_layout Subsubsection*
Memory
\end_layout

\begin_layout Standard
Multiple types of memory are needed.
 Most important (for demo purposes) is memory consisting of imperatives:
 when she is told to do this and say that, she needs to remember this, and
 later on, play that back as a performance.
\end_layout

\begin_layout Standard
This should be 
\begin_inset Quotes eld
\end_inset

straight-forward
\begin_inset Quotes erd
\end_inset

: one can record the control-language directives.
 They need to be marked up with timing information.
\end_layout

\begin_layout Standard
Implementing acting-coaching is interesting, and in particular, implementing
 directives such as 
\begin_inset Quotes eld
\end_inset

do that performance again, except this time, make xyz go more slowly
\begin_inset Quotes erd
\end_inset

.
\end_layout

\begin_layout Standard
A second type of memory would be remembering past states of the world.
\end_layout

\begin_layout Standard
One technical challenge is that we will need a management layer for the
 Postgres DB interfaces, so that memories are not lost during power-off.
 Those memories need to be segregated: there are somethings that need to
 be remembered, others that should not be.
\end_layout

\begin_layout Subsubsection*
Learning from sensory input
\end_layout

\begin_layout Standard
Creating atomese representations of sensory input processing pipelines,
 so that specific sensory inputs can be recognized e.g.
 if the audio volume suddenly got loud, and the visual field is suddenly
 moving, then maybe ...
 everyone is clapping? booing? getting up to leave? ...I'm no longer the center
 of attention?
\end_layout

\begin_layout Subsubsection*
Free will
\end_layout

\begin_layout Standard
Free will, as defined here, is the over-riding of default behavior (as computed
 by psi-rules) by means of a logically, rationally reasoned course of action.
 For example, the default of the psi rules might be 
\begin_inset Quotes eld
\end_inset

lolly-gag about
\begin_inset Quotes erd
\end_inset

, while a rational decision would be 
\begin_inset Quotes eld
\end_inset

go and do that important thing
\begin_inset Quotes erd
\end_inset

.
 Free will is then the act of picking between these two alternatives, of
 balancing them out (at a critical phase-transition point).
\end_layout

\begin_layout Section*
Items
\end_layout

\begin_layout Itemize
a person walks into room, who she recognizes.
 Depending on psi, she should do non-verbal greetings (play one of 3-4 different
 animations (look at, chin push, nod)) and verbal greetings (
\begin_inset Quotes eld
\end_inset

hello, what's up, yo dawg
\begin_inset Quotes erd
\end_inset

).
 split up the state and the psi rule stuff properly.
 See comments here: https://github.com/opencog/ros-behavior-scripting/pull/80
 
\end_layout

\begin_layout Itemize
extract keywords/key-topics from sentence, and remember them, then apply
 fuzzy matcher to see which of these come up.
\end_layout

\begin_layout Section*
Random ideas
\end_layout

\begin_layout Itemize
Why did you smile? Output: have her explain recent openpsi decision-making.
\end_layout

\begin_layout Itemize
I'm so sorry about that.
 Output: a small cute pout (blend of frown and ???)
\end_layout

\begin_layout Itemize
Look at me.
 (verify look-at location or report visibility)
\end_layout

\begin_layout Itemize
What are you doing? 
\end_layout

\begin_layout Itemize
(When last person leaves, she should say goodbye.
 If did not say goodbye, then say 
\begin_inset Quotes eld
\end_inset

hey where did everybody go?
\begin_inset Quotes erd
\end_inset

)
\end_layout

\begin_layout Itemize
If no one is visible, and no one has been visible for many minutes, she
 should say 
\begin_inset Quotes eld
\end_inset

hey where did everybody go?
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Behavior -- she should not get sleepy, as long as someone is visible.
\end_layout

\begin_layout Itemize
Behavior -- she should complain, if no one is visible, but there is a chat
 session going on.
\end_layout

\end_body
\end_document
